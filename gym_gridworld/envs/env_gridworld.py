import os
import gym
import sys
import copy
import numpy as np

from gym import spaces

from PIL import Image as Image
import matplotlib.pyplot as plt

# ê·¸ë¦¬ë“œ ê° ìš”ì†Œë“¤ì˜ ìƒ‰ê¹” ì§€ì •í•´ì¤Œ
COLORS = {0: [0.0, 0.0, 0.0], 1: [0.5, 0.5, 0.5],
          2: [0.0, 1.0, 0.0], 3: [1.0, 0.0, 0.0],
          4: [0.0, 0.0, 1.0], 5: [1.0, 0.5, 0.0] }


class GridworldEnv(gym.Env):
    num_env = 0 

    #ğŸ”¥ğŸ”¥ğŸ”¥
    def __init__(self):
        # Action space
        #              [ê°€ë§Œíˆ, ìœ„, ì•„ë˜, ì¢Œ, ìš°]
        self.actions = [0, 1, 2, 3, 4]
        self.action_space = spaces.Discrete(5)

        # í–‰ê°’ì€ ìƒí•˜
        # ì—´ê°’ì€ ì¢Œìš°ë¡œ ì´ë™ ì‹œí‚´
        #                           ê°€ë§Œíˆ      ìœ„          ì•„ë˜       ì¢Œ          ìš°     
        # self.action_pos_dict = { 0: [0, 0], 1: [-1, 0], 2: [1, 0], 3: [0, -1], 4: [0, 1] }
        self.action_pos_dict = { 0: [0, 0], 1: [-1, 0], 2: [1, 0], 3: [0, -1], 4: [0, 1]}

        # self.action_pos_dict[1] ----> [-1, 0]
        # self.action_pos_dict[1][0] ----> -1

        # Observation space
        self.obs_shape = [9,16]#[128, 128, 3]  # Observation space shape
        self.observation_space = spaces.Box(
            low=0, high=1, shape=self.obs_shape, dtype=np.float32)

        # Construct grid map
        file_path = os.path.dirname(os.path.realpath(__file__))
        #os.path.realpath(__file__)   í‘œì¤€ê²½ë¡œ + ì´ë¦„ ë¶ˆëŸ¬ì˜´

        self.grid_map_path = os.path.join(file_path, 'maplemap.txt') 
        # íŒŒì¼ ê²½ë¡œì— map.txtë¥¼ ë¶™ì—¬ì„œ ê²½ë¡œ ë§Œë“œëŠ” ê±°ì„
        # text íŒŒì¼ë¡œ ë§µ ì •ì˜í–ˆì—ˆìŒ


        self.initial_map = self.read_grid_map(self.grid_map_path)   # ì•„ë˜ì— êµ¬í˜„ëœ í•¨ìˆ˜ ìˆìŒ.
        #                                                             ë§µ ê°’ì„ np.ndarrayë¡œ ë¶ˆëŸ¬ì˜´.


        self.current_map = copy.deepcopy(self.initial_map)          # ë³µì‚¬í•´ì˜´
        self.observation = self.gridmap_to_observation(self.initial_map)  # í™˜ê²½ ë§µ(np.ndarray) ê·¸ ìì²´ë¥¼ ë„£ì–´ì¤Œ.
        #                                                                   í•¨ìˆ˜ ì„¤ëª…ì€ ì•„ë˜ì— ìˆìŒ.
        self.grid_shape = self.initial_map.shape # (16, 16)

        # Agent actions
        # stateëŠ” ì¢Œí‘œë“¤ì„.
        self.start_state, self.target_state, self.Final_state = self.get_agent_states(self.initial_map)

        # ì—ì´ì „íŠ¸ì˜ ì´ˆê¸° stateëŠ” start_stateë¡œ ì¤Œ.
        self.agent_state = copy.deepcopy(self.start_state)


        # Set other parameters
        GridworldEnv.num_env += 1
        self.fig_num = GridworldEnv.num_env
        self.fig = plt.figure(self.fig_num)
        plt.show(block=False)
        plt.axis('off')


    #ğŸ”¥ğŸ”¥ğŸ”¥
    def step(self, action):

        #                [ê°€ë§Œíˆ, ìœ„, ì•„ë˜, ì¢Œ, ìš°]
        # self.actions = [0,      1,    2,  3,  4]


        # agent_stateë¼ëŠ” ê°’ì—ëŠ” ë§µì—ì„œì˜ ì¢Œí‘œê°’ì´ ë“¤ì–´ê°.

        action = int(action)

        # next_state = (x, x)
        # í–‰ê°’ì€ ìƒí•˜, ì—´ê°’ì€ ì¢Œìš°ë¡œ ì´ë™ì‹œí‚´
        #                             ì œìë¦¬      ìœ„          ì•„ë˜       ì¢Œ          ìš°
        # self.action_pos_dict = { 0: [0, 0], 1: [-1, 0], 2: [1, 0], 3: [0, -1], 4: [0, 1]}

        # e.g. ì—ì´ì „íŠ¸ëŠ” ì²˜ìŒì— [2, 2]ì— ìˆì—ˆìŒ.
        # actionì´ 2ì´ë¼ê³  í•˜ë©´
        # next_state = (2 + self.action_pos_dict[2][0],
        #               2 + self.action_pos_dict[2][1])ì´ ë¨.
        #
        # next_state = (2 + 1,
        #               2 + 0)ê°€ ë˜ëŠ” ê±°ì„. -----> ì¢Œí‘œ (3, 2)ë¡œ ì´ë™í•¨. -----> ì—´ì€ ê·¸ëŒ€ë¡œê³ , í•œ í–‰ ì•„ë˜ë¡œ ì´ë™.
        #               ì•„ë˜ë¡œ ì´ë™í•˜ëŠ” actionì„ í•´ì£¼ëŠ” ê±°ì„.
        # next_state = [3, 2] ì¶œë ¥í•´ì¤Œ.
        next_state = (self.agent_state[0] + self.action_pos_dict[action][0],
                      self.agent_state[1] + self.action_pos_dict[action][1])




        # Stay in place
        # ì œìë¦¬ actionì„ í•˜ë©´....
        # (ì›ë˜ì˜ observation, reward=0, dond=False)ë¥¼ ì—ì´ì „íŠ¸ì—ê²Œ ì¤€ë‹¤.
        if action == 0:
            return (self.observation, 0, False)

        # Out of bounds condition
        # ê²œ ë§µì„ ë²—ì–´ë‚˜ë ¤ëŠ” ê²½ìš°ì— í•´ë‹¹.
        # grid_shapeëŠ” [16, 16]ì— í•´ë‹¹í•¨.
        # ì—ì´ì „íŠ¸ê°€ ê²½ê³„ë¥¼ ë²—ì–´ë‚˜ëŠ” ë™ì‘ì„ í•˜ë ¤ê³  í•˜ë©´ 'ì œìë¦¬ action'ìœ¼ë¡œ ë§‰ì•„ì¤Œ.
        if next_state[0] < 0 or next_state[0] >= self.grid_shape[0]:
            return (self.observation, 0, False)
        if next_state[1] < 0 or next_state[1] >= self.grid_shape[1]:
            return (self.observation, 0, False)



        # current_mapì€ ìœ„ì™€ ê°™ì´ ìƒê²¼ìŒ.
        # ì§„í–‰ ìƒí™©ì— ë”°ë¼ ê° ì¹¸ì˜ ê°’ì€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ.
        # agent_stateëŠ” [2, 2]ì™€ ê°™ì€ ì¢Œí‘œê°’ì„ ë§í•¨. ----> [2, 2]ë¼ê³  ì˜ˆë¥¼ ë“¤ê² ìŒ.
        # ë§µì˜ ê° ìœ„ì¹˜ì—ëŠ” ì»¬ëŸ¬ ê°’ì´ ì“°ì—¬ ìˆìŒ.  # 0: Black; 1: Gray; 2: Green; 3: Red, 4: Blue 5: yellow
        # 0: ê·¸ëƒ¥ ê¸¸, 1: ë²½, 2: ê°€ì‹œë¤ë¶ˆ, 3: ì—ì´ì „íŠ¸
        # cur_color = self.current_map[2, 2] = 3ì´ ë‚˜ì˜´
        cur_color = self.current_map[self.agent_state[0], self.agent_state[1]]

        # ì—ì´ì „íŠ¸ê°€ ì´ë™í•œ ìœ„ì¹˜ì—ì„œì˜ ì»¬ëŸ¬ê°’ì„ ê°€ì ¸ì˜´.
        new_color = self.current_map[next_state[0], next_state[1]]

        # ìƒˆë¡œ ì´ë™í•˜ë ¤ëŠ” ìœ„ì¹˜ì˜ ì»¬ëŸ¬ê°’ì´ 1(ë²½)ì´ë©´
        if new_color == 1:        # ì§€ê¸ˆ ê·¸ëŒ€ë¡œì˜ ê°’ë“¤ì„ ë‚´ë³´ë‚´ì¤Œ
            return (self.observation, 0, False)

        # ìƒˆë¡œ ì´ë™í•˜ë ¤ëŠ” ìœ„ì¹˜ì˜ ì»¬ëŸ¬ê°’ì´ 0(ê·¸ëƒ¥ ê¸¸)ì´ë©´... 
        elif new_color == 0:  # Black - empty

            # ê·¸ë¦¬ê³  í˜„ì¬ ìœ„ì¹˜ì˜ ì»¬ëŸ¬ê°’ì´ 3(ì—ì´ì „íŠ¸)ì´ë©´...
            if cur_color == 3:
                # ì¸ê°„ì´ ë³´ê¸° ì‰½ë„ë¡ ê·¸ë¦¬ë“œì˜ ìƒ‰ê¹”ì„ ì„œë¡œ ë°”ê¿”ì¤Œ.
                self.current_map[self.agent_state[0], self.agent_state[1]] = 0
                self.current_map[next_state[0], next_state[1]] = 3
            self.agent_state = copy.deepcopy(next_state)
            self.observation = self.gridmap_to_observation(self.current_map)
            return (self.observation, 0, False)
       
        # ìƒˆë¡œ ì´ë™í•˜ë ¤ëŠ” ìœ„ì¹˜ì˜ ì»¬ëŸ¬ê°’ì´ 2(ê°€ì‹œë¤ë¶ˆ)ì´ë©´
        elif new_color == 2:

            #ê·¸ë¦¬ê³  í˜„ì¬ ìœ„ì¹˜ì˜ ì»¬ëŸ¬ê°’ì´ 3(ì—ì´ì „íŠ¸)ì´ë©´
            if cur_color ==3:
                #í˜„ì¬ìœ„ì¹˜ì˜ ê°’ì€ ê¸¸ì˜ ìƒ‰ìœ¼ë¡œ ë³€ê²½,  ì´ë™í•œ ë°œíŒì„ agentìƒ‰ìœ¼ë¡œ ë³€ê²½
                self.current_map[self.agent_state[0],self.agent_state[1]] = 0
                self.current_map[next_state[0],next_state[1]] = 3
            self.agent_state = copy.deepcopy(next_state)
            self.observation = self.gridmap_to_observation(self.current_map)
            return (self.observation, -0.1, False)

            # # í˜„ì¬ ìœ„ì¹˜ì˜ ìƒ‰ê¹”ì„ 0(ê²€ì •)ìœ¼ë¡œ í•´ì¤Œ.
            # self.current_map[self.agent_state[0], self.agent_state[1]] = 0
            # # ë§Œì•½ ìœ„ì—ì„œ ì™”ë‹¤ë©´



            # self.current_map[next_state[0], next_state[1]] = 2
            # '''
            # # ê¸°ë³¸ ë°œíŒì˜ ìƒ‰ì„ 2(ê°€ì‹œë¤ë¶ˆ)ë¡œ ìœ ì§€
            # # ë°œíŒì„ 2ë²ˆ ë„˜ì–´ê° ìƒˆë¡œ ì´ë™í•œ ìœ„ì¹˜ì˜ ìƒ‰ê¹”ì„ 3(agent)ìœ¼ë¡œ ë°”ê¿ˆ
            # self.current_map[next_state[0], next_state[1]] = 2
            # self.current_map[next_state[0]+self.action_pos_dict[action][0], next_state[1]+self.action_pos_dict[action][1]] = 3
            # self.agent_state = copy.deepcopy(tuple(list(next_state).__add__(self.action_pos_dict[action])))
            # '''
        #ìƒˆë¡œ ì´ë™í•˜ë ¤ëŠ” ìœ„ì¹˜ì˜ ì»¬ëŸ¬ê°’ì´ 4(ì¿ í‚¤)ì´ë©´    
        elif new_color == 4:
            # í˜„ì¬ ìœ„ì¹˜ì˜ ìƒ‰ê¹”ì„ 0(ê²€ì •)ìœ¼ë¡œ í•´ì¤Œ.
            self.current_map[self.agent_state[0], self.agent_state[1]] = 0

            self.current_map[next_state[0], next_state[1]] = 3
            self.agent_state = copy.deepcopy(next_state)

            # for i in range(len(self.target_state)):
            #     if next_state == self.target_state[i]:
            #         r+=1
            self.observation = self.gridmap_to_observation(self.current_map)
            return(self.observation,1,False)

        elif new_color ==5:
            self.current_map[self.agent_state[0], self.agent_state[1]] = 0
            self.current_map[next_state[0], next_state[1]] = 3
            self.agent_state = copy.deepcopy(next_state)            
            self.observation = self.gridmap_to_observation(self.current_map)
            


            return(self.observation, 100, True)  


                     
            

        # ìœ„ ê³¼ì •ì„ ê±°ì¹¨ì— ë”°ë¼ ì²˜ìŒì— ë´¤ë˜ grid_mapê³¼ shapeì€ ê°™ì§€ë§Œ ê° ì¹¸ì˜ ê°’ì´ ë‹¬ë¼ì§ˆ ê±°ì„.
        # ì§€ê¸ˆ í˜„ì¬ì˜ map ìƒí™©ì„ ì—ì´ì „íŠ¸ì—ê²Œ observationìœ¼ë¡œ ì œê³µí•´ì¤„ ê±°ì„.
        # self.observation = self.gridmap_to_observation(self.current_map)
        # if next_state in self.target_state:
        #     target_observation = copy.deepcopy(self.observation)
        #     return(target_observation,1,True)
        # else:
        #     return(self.observation,0,False)
        # for i in range(len(self.target_state)):
        #     if next_state == self.target_state[i]:
        #         r+=1
        #     target_observation = copy.deepcopy(self.observation)
        #     return(target_observation,r,True)
        
        
            

        # if next_state[0] == self.target_state[0] and next_state[1] == self.target_state[1]:
        #     target_observation = copy.deepcopy(self.observation)
        #     self.reset()


    #ğŸ”¥ğŸ”¥ğŸ”¥
    # ëª¨ë“  ê±¸ initialization
    def reset(self):
        self.agent_state = copy.deepcopy(self.start_state)
        self.current_map = copy.deepcopy(self.initial_map)
        self.observation = self.gridmap_to_observation(self.initial_map)
        return self.observation

    # ê·¸ë¦¼ ë³´ì—¬ì£¼ê¸°
    def render(self):
        img = self.observation
        plt.clf()
        plt.imshow(img)
        self.fig.canvas.draw()
        plt.pause(0.00001)


    def read_grid_map(self, grid_map_path):
        with open(grid_map_path, 'r') as f: # ì–´ë–¤ íŒŒì¼(mapì— ëŒ€í•œ txt íŒŒì¼)ì„ ì—¬ëŠ”ë° fë¼ê³  ì§€ì¹­í•˜ê² ìŒ
            grid_map = f.readlines()  # readlines() í•´ì£¼ë©´, DataFrameí•œ ê²ƒì²˜ëŸ¼ txt íŒŒì¼ ë‚´ìš© ì „ë¶€ ê°€ì ¸ì˜´.




        
            # list ----> ì¼ë‹¨ ë…¼ì™¸
            # map  ----> së¥¼ xë¼ëŠ” ë³€ìˆ˜ë¡œ ë°”ê¿”ì£¼ê³  ë’¤ì— ìˆëŠ”   list(~~~~)ì— ë§µí•‘ ì‹œì¼œì¤Œ.
            # list ----> ì´ê²ƒë„ ì¼ë‹¨ ë…¼ì™¸
            # map  ----> xê°€ x.split(' ')ë¡œ ë¶„ë¦¬ë¨.

            # x.split(' ') ----> ê³µë°±ì„ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ ë¶„ë¦¬
            # lambda y: int(y) ----> ì—¬ê¸°ì— ë§µí•‘í•´ì„œ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜
            # ë‹¤ì‹œ ê´„í˜¸ ë°”ê¹¥ìª½ìœ¼ë¡œ ë‚˜ê°€ì¤Œ.

            # list(          map(lambda x:   list( map( lambda y: int(y),   x.split(' ') ) ),    s)        )


        grids = np.array(   list(map(lambda x:
                                  list(map(lambda y: int(y),
                                           x.split(' '))), grid_map))   )




        return grids
        # gridsëŠ” ì•„ë˜ì™€ ê°™ì´ ìƒê²¼ìŒ.
        # ë§µì„ np.ndarrayë¡œ ë¶ˆëŸ¬ì˜´.
        # ìœ„ mapì„ í•¨ìˆ˜ ì •ì˜ ë°–ì— ì“°ë©´ ì´ìƒí•œ ë°‘ì¤„ ë‚˜ì™€ì„œ ì €ë ‡ê²Œ ì¼ìŒ. ì´ìœ ëŠ” ëª¨ë¦„.




    def get_agent_states(self, initial_map):
        start_state = None
        target_state = None
        Final_state = None


        # 3ì€ ì‹œì‘ì ì„ ì˜ë¯¸
        # np.where ----> (array([2],  dtype=int64), array([2], dtype=int64))
        # list(map( lambda x: x[0],   np.where(grids == 3)  ))  ---->  [2, 2] = start_state
        start_state = list(map(
            lambda x: x[0] if len(x) > 0 else None,
            np.where(initial_map == 3)
        ))
        Final_state = list(map(
            lambda x: x[0] if len(x) > 0 else None,
            np.where(Final_state == 5)
        ))

        k = np.where(initial_map == 4)
        target_state = np.append(k[0],k[1]).reshape(2,-1).T.tolist()


        if start_state == [None, None] or target_state == [None, None]:
            sys.exit('Start or target state not specified')

        # [2, 2], [11, 4]
        return start_state, target_state, Final_state



    def gridmap_to_observation(self, grid_map, obs_shape=None):

        observation = grid_map
        return observation
